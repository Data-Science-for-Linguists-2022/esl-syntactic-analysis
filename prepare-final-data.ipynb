{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Final Data Preparation\n",
    "\n",
    "After exploring the TAASSC output for the first 100 rows of the PELIC dataset (and seeing how painfully slow the process was), I'm now ready to create the final dataset for the project, generate its syntactical measures with TAASSC, and perform some actual statistical analysis."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Final Dataset\n",
    "\n",
    "Since TAASSC would take ages to process the whole dataset, I'm going to only work with a much smaller (though still much bigger than the first 100 rows) subset of the data.\n",
    "I also remembered that some L1s and proficiency levels had very few students to begin with, which I worried could skew the results for those L1-proficiency combinations, so after some deliberation I decided that I'll only work with the most common L1s and proficiency levels.\n",
    "This should also help limit the size of the final dataset (and thereby also reduce the TAASSC processing time)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   answer_id anon_id       L1  gender   semester  placement_test  course_id  \\\n0          1     eq0   Arabic    Male  2006_fall             NaN        149   \n1          2     am8     Thai  Female  2006_fall             NaN        149   \n2          3     dk5  Turkish  Female  2006_fall             NaN        115   \n3          4     dk5  Turkish  Female  2006_fall             NaN        115   \n4          5     ad1   Korean  Female  2006_fall             NaN        115   \n\n   level_id class_id  question_id  version  text_len  \\\n0         4        g            5        1       177   \n1         4        g            5        1       137   \n2         4        w           12        1        63   \n3         4        w           13        1         6   \n4         4        w           12        1        59   \n\n                                                text  \\\n0  I met my friend Nife while I was studying in a...   \n1  Ten years ago, I met a women on the train betw...   \n2  In my country we usually don't use tea bags. F...   \n3              I organized the instructions by time.   \n4  First, prepare a port, loose tea, and cup.\\nSe...   \n\n                                              tokens  \\\n0  ['I', 'met', 'my', 'friend', 'Nife', 'while', ...   \n1  ['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...   \n2  ['In', 'my', 'country', 'we', 'usually', 'do',...   \n3  ['I', 'organized', 'the', 'instructions', 'by'...   \n4  ['First', ',', 'prepare', 'a', 'port', ',', 'l...   \n\n                                         tok_lem_POS  \n0  [('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...  \n1  [('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...  \n2  [('In', 'in', 'IN'), ('my', 'my', 'PRP$'), ('c...  \n3  [('I', 'I', 'PRP'), ('organized', 'organize', ...  \n4  [('First', 'first', 'RB'), (',', ',', ','), ('...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answer_id</th>\n      <th>anon_id</th>\n      <th>L1</th>\n      <th>gender</th>\n      <th>semester</th>\n      <th>placement_test</th>\n      <th>course_id</th>\n      <th>level_id</th>\n      <th>class_id</th>\n      <th>question_id</th>\n      <th>version</th>\n      <th>text_len</th>\n      <th>text</th>\n      <th>tokens</th>\n      <th>tok_lem_POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>eq0</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>149</td>\n      <td>4</td>\n      <td>g</td>\n      <td>5</td>\n      <td>1</td>\n      <td>177</td>\n      <td>I met my friend Nife while I was studying in a...</td>\n      <td>['I', 'met', 'my', 'friend', 'Nife', 'while', ...</td>\n      <td>[('I', 'I', 'PRP'), ('met', 'meet', 'VBD'), ('...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>am8</td>\n      <td>Thai</td>\n      <td>Female</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>149</td>\n      <td>4</td>\n      <td>g</td>\n      <td>5</td>\n      <td>1</td>\n      <td>137</td>\n      <td>Ten years ago, I met a women on the train betw...</td>\n      <td>['Ten', 'years', 'ago', ',', 'I', 'met', 'a', ...</td>\n      <td>[('Ten', 'ten', 'CD'), ('years', 'year', 'NNS'...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>dk5</td>\n      <td>Turkish</td>\n      <td>Female</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>115</td>\n      <td>4</td>\n      <td>w</td>\n      <td>12</td>\n      <td>1</td>\n      <td>63</td>\n      <td>In my country we usually don't use tea bags. F...</td>\n      <td>['In', 'my', 'country', 'we', 'usually', 'do',...</td>\n      <td>[('In', 'in', 'IN'), ('my', 'my', 'PRP$'), ('c...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>dk5</td>\n      <td>Turkish</td>\n      <td>Female</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>115</td>\n      <td>4</td>\n      <td>w</td>\n      <td>13</td>\n      <td>1</td>\n      <td>6</td>\n      <td>I organized the instructions by time.</td>\n      <td>['I', 'organized', 'the', 'instructions', 'by'...</td>\n      <td>[('I', 'I', 'PRP'), ('organized', 'organize', ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>ad1</td>\n      <td>Korean</td>\n      <td>Female</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>115</td>\n      <td>4</td>\n      <td>w</td>\n      <td>12</td>\n      <td>1</td>\n      <td>59</td>\n      <td>First, prepare a port, loose tea, and cup.\\nSe...</td>\n      <td>['First', ',', 'prepare', 'a', 'port', ',', 'l...</td>\n      <td>[('First', 'first', 'RB'), (',', ',', ','), ('...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic = pd.read_csv(\"data/PELIC_compiled.csv\")\n",
    "pelic.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "First take another look at the L1 speaker counts:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                   L1  Count\n0              Arabic    439\n1             Chinese    220\n2              Korean    214\n3            Japanese     67\n4             Spanish     57\n5             Turkish     40\n6                Thai     31\n7          Portuguese     17\n8               Other     14\n9             Italian     12\n10          Taiwanese     12\n11             French     10\n12            Russian      9\n13             Hebrew      6\n14              Farsi      4\n15             German      3\n16             Mongol      3\n17         Vietnamese      3\n18         Indonesian      2\n19             Polish      2\n20            English      2\n21        Azerbaijani      2\n22           Romanian      1\n23            Swedish      1\n24             Suundi      1\n25            Swahili      1\n26              Hindi      1\n27  Russian,Ukrainian      1\n28        Montenegrin      1\n29               Zulu      1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>L1</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Arabic</td>\n      <td>439</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Chinese</td>\n      <td>220</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Korean</td>\n      <td>214</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Japanese</td>\n      <td>67</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Spanish</td>\n      <td>57</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Turkish</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Thai</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Portuguese</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Other</td>\n      <td>14</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Italian</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Taiwanese</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>French</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Russian</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Hebrew</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Farsi</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>German</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Mongol</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Vietnamese</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Indonesian</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Polish</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>English</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Azerbaijani</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Romanian</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Swedish</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Suundi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Swahili</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Hindi</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Russian,Ukrainian</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Montenegrin</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>Zulu</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_counts = pelic.drop_duplicates(\"anon_id\").L1.value_counts()\n",
    "L1_counts = L1_counts.reset_index()\n",
    "L1_counts.rename(columns={\"L1\": \"Count\", \"index\": \"L1\"}, inplace=True)\n",
    "L1_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 with more than 30 speakers:\n",
      "Arabic\n",
      "Chinese\n",
      "Korean\n",
      "Japanese\n",
      "Spanish\n",
      "Turkish\n",
      "Thai\n"
     ]
    }
   ],
   "source": [
    "biggest_L1s = L1_counts[L1_counts[\"Count\"] > 30][\"L1\"]\n",
    "\n",
    "print(\"L1 with more than 30 speakers:\")\n",
    "for L1 in biggest_L1s:\n",
    "    print(L1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker counts by level for L1s with more than 30 speakers:\n"
     ]
    },
    {
     "data": {
      "text/plain": "          L1  Level  Count\n1     Arabic      3    244\n2     Arabic      4    342\n3     Arabic      5    212\n7    Chinese      3     86\n8    Chinese      4    154\n9    Chinese      5     96\n33  Japanese      3     21\n34  Japanese      4     53\n35  Japanese      5     35\n37    Korean      3     88\n38    Korean      4    151\n39    Korean      5    112\n58   Spanish      3     18\n59   Spanish      4     40\n60   Spanish      5     25\n69      Thai      3     10\n70      Thai      4     25\n71      Thai      5     17\n72   Turkish      3     24\n73   Turkish      4     32\n74   Turkish      5     12",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>L1</th>\n      <th>Level</th>\n      <th>Count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Arabic</td>\n      <td>3</td>\n      <td>244</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arabic</td>\n      <td>4</td>\n      <td>342</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arabic</td>\n      <td>5</td>\n      <td>212</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Chinese</td>\n      <td>3</td>\n      <td>86</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Chinese</td>\n      <td>4</td>\n      <td>154</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Chinese</td>\n      <td>5</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>Japanese</td>\n      <td>3</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Japanese</td>\n      <td>4</td>\n      <td>53</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>Japanese</td>\n      <td>5</td>\n      <td>35</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>Korean</td>\n      <td>3</td>\n      <td>88</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>Korean</td>\n      <td>4</td>\n      <td>151</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>Korean</td>\n      <td>5</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>Spanish</td>\n      <td>3</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>59</th>\n      <td>Spanish</td>\n      <td>4</td>\n      <td>40</td>\n    </tr>\n    <tr>\n      <th>60</th>\n      <td>Spanish</td>\n      <td>5</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>69</th>\n      <td>Thai</td>\n      <td>3</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>70</th>\n      <td>Thai</td>\n      <td>4</td>\n      <td>25</td>\n    </tr>\n    <tr>\n      <th>71</th>\n      <td>Thai</td>\n      <td>5</td>\n      <td>17</td>\n    </tr>\n    <tr>\n      <th>72</th>\n      <td>Turkish</td>\n      <td>3</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Turkish</td>\n      <td>4</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>74</th>\n      <td>Turkish</td>\n      <td>5</td>\n      <td>12</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_level_counts = pelic.groupby([\"L1\", \"level_id\"])[\"anon_id\"].nunique()\n",
    "L1_level_counts = L1_level_counts.reset_index()\n",
    "L1_level_counts.rename(columns={\"level_id\": \"Level\", \"anon_id\": \"Count\"}, inplace=True)\n",
    "\n",
    "print(\"Speaker counts by level for L1s with more than 30 speakers:\")\n",
    "biggest_L1_counts = L1_level_counts[\n",
    "    L1_level_counts[\"L1\"].isin(list(biggest_L1s)) &\n",
    "    L1_level_counts[\"Level\"].isin([3, 4, 5])\n",
    "]\n",
    "biggest_L1_counts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how many essays there are for these L1s:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "42146"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pelic[pelic[\"L1\"].isin(list(biggest_L1s))])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Okay... so that's still *way* too many to process in a reasonable amount of time.\n",
    "Instead, I think I'll select a sample of *students* for each combination of L1 and proficiency level and work specifically with the essays from those students.\n",
    "This should also ensure that the syntactic measures later on are more evenly distributed so that no L1 or proficiency level dominate the dataset.\n",
    "\n",
    "Note: there may be cases of a student being selected for more than one proficiency level, but I don't think that should be a significant issue."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The list of students for a specific L1 and proficiency level could be created as follows:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['eu0', 'fw3', 'af0', 'ci6', 'cs1', 'ei3', 'be8', 'gy1', 'cf3',\n       'gt4'], dtype=object)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pelic[(pelic[\"L1\"] == \"Thai\") & (pelic[\"level_id\"] == 3)][\"anon_id\"].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "46204"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pelic)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "      answer_id anon_id      L1 gender   semester  placement_test  course_id  \\\n439         478     bd3  Arabic   Male  2006_fall             NaN         98   \n440         479     bd3  Arabic   Male  2006_fall             NaN        110   \n555         595     bd3  Arabic   Male  2006_fall             NaN         98   \n1056       1101     bd3  Arabic   Male  2006_fall             NaN        110   \n1305       1364     bd3  Arabic   Male  2006_fall             NaN        110   \n\n      level_id class_id  question_id  version  text_len  \\\n439          3        r           29        1       177   \n440          3        w           50        1       256   \n555          3        r           29        2       234   \n1056         3        w           99        1       130   \n1305         3        w          120        1       143   \n\n                                                   text  \\\n439   (Mismanagement)\\nSentence: … their would be no...   \n440   Hospitality in Saudi Arabia\\n\\n The hospitalit...   \n555   Vocabulary:\\n\\n(Mismanagement)\\nSentence: … th...   \n1056  October 17, 2006\\n\\nDear basma,\\n\\n I thought ...   \n1305  October 17, 2006\\n\\nDear basma,\\n\\nI thought a...   \n\n                                                 tokens  \\\n439   ['(', 'Mismanagement', ')', 'Sentence', ':', '...   \n440   ['Hospitality', 'in', 'Saudi', 'Arabia', 'The'...   \n555   ['Vocabulary', ':', '(', 'Mismanagement', ')',...   \n1056  ['October', '17', ',', '2006', 'Dear', 'basma'...   \n1305  ['October', '17', ',', '2006', 'Dear', 'basma'...   \n\n                                            tok_lem_POS  \n439   [('(', '(', '('), ('Mismanagement', 'Mismanage...  \n440   [('Hospitality', 'hospitality', 'NN'), ('in', ...  \n555   [('Vocabulary', 'Vocabulary', 'JJ'), (':', ':'...  \n1056  [('October', 'October', 'NNP'), ('17', '17', '...  \n1305  [('October', 'October', 'NNP'), ('17', '17', '...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answer_id</th>\n      <th>anon_id</th>\n      <th>L1</th>\n      <th>gender</th>\n      <th>semester</th>\n      <th>placement_test</th>\n      <th>course_id</th>\n      <th>level_id</th>\n      <th>class_id</th>\n      <th>question_id</th>\n      <th>version</th>\n      <th>text_len</th>\n      <th>text</th>\n      <th>tokens</th>\n      <th>tok_lem_POS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>439</th>\n      <td>478</td>\n      <td>bd3</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>98</td>\n      <td>3</td>\n      <td>r</td>\n      <td>29</td>\n      <td>1</td>\n      <td>177</td>\n      <td>(Mismanagement)\\nSentence: … their would be no...</td>\n      <td>['(', 'Mismanagement', ')', 'Sentence', ':', '...</td>\n      <td>[('(', '(', '('), ('Mismanagement', 'Mismanage...</td>\n    </tr>\n    <tr>\n      <th>440</th>\n      <td>479</td>\n      <td>bd3</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>110</td>\n      <td>3</td>\n      <td>w</td>\n      <td>50</td>\n      <td>1</td>\n      <td>256</td>\n      <td>Hospitality in Saudi Arabia\\n\\n The hospitalit...</td>\n      <td>['Hospitality', 'in', 'Saudi', 'Arabia', 'The'...</td>\n      <td>[('Hospitality', 'hospitality', 'NN'), ('in', ...</td>\n    </tr>\n    <tr>\n      <th>555</th>\n      <td>595</td>\n      <td>bd3</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>98</td>\n      <td>3</td>\n      <td>r</td>\n      <td>29</td>\n      <td>2</td>\n      <td>234</td>\n      <td>Vocabulary:\\n\\n(Mismanagement)\\nSentence: … th...</td>\n      <td>['Vocabulary', ':', '(', 'Mismanagement', ')',...</td>\n      <td>[('Vocabulary', 'Vocabulary', 'JJ'), (':', ':'...</td>\n    </tr>\n    <tr>\n      <th>1056</th>\n      <td>1101</td>\n      <td>bd3</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>110</td>\n      <td>3</td>\n      <td>w</td>\n      <td>99</td>\n      <td>1</td>\n      <td>130</td>\n      <td>October 17, 2006\\n\\nDear basma,\\n\\n I thought ...</td>\n      <td>['October', '17', ',', '2006', 'Dear', 'basma'...</td>\n      <td>[('October', 'October', 'NNP'), ('17', '17', '...</td>\n    </tr>\n    <tr>\n      <th>1305</th>\n      <td>1364</td>\n      <td>bd3</td>\n      <td>Arabic</td>\n      <td>Male</td>\n      <td>2006_fall</td>\n      <td>NaN</td>\n      <td>110</td>\n      <td>3</td>\n      <td>w</td>\n      <td>120</td>\n      <td>1</td>\n      <td>143</td>\n      <td>October 17, 2006\\n\\nDear basma,\\n\\nI thought a...</td>\n      <td>['October', '17', ',', '2006', 'Dear', 'basma'...</td>\n      <td>[('October', 'October', 'NNP'), ('17', '17', '...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(69)\n",
    "\n",
    "essay_samples = []\n",
    "for L1 in biggest_L1s:\n",
    "    for level in [3, 4, 5]:\n",
    "        students = list(pelic[(pelic[\"L1\"] == L1) & (pelic[\"level_id\"] == level)][\"anon_id\"].unique())\n",
    "        student_sample = random.sample(students, k=10)\n",
    "        essay_samples.append(\n",
    "            pelic[\n",
    "                (pelic[\"L1\"] == L1) &\n",
    "                (pelic[\"level_id\"] == level) &\n",
    "                (pelic[\"anon_id\"].isin(student_sample))\n",
    "            ]\n",
    "        )\n",
    "\n",
    "essay_samples = pd.concat(essay_samples)\n",
    "essay_samples.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thankfully the size of the dataset has been *significantly* reduced:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "4341"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(essay_samples)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# for i in range(len(essay_samples)):\n",
    "#     with open(f\"data_samples/text/{essay_samples.iloc[i]['answer_id']}.txt\", \"w\") as f:\n",
    "#         f.write(essay_samples.iloc[i][\"text\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## TAASSC Processing 2: Electric Boogaloo\n",
    "\n",
    "Now that TAASSC has finally finished processing all of the data samples, it's time to construct and clean up the syntactic measure data.\n",
    "This is pretty much identical to what I did in `taassc-prep.ipynb`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "taassc = pd.read_csv(\"data_samples/samples_taassc.csv\")\n",
    "taassc_sca = pd.read_csv(\"data_samples/samples_taassc_sca.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "    filename  nwords  cl_av_deps  cl_ndeps_std_dev  acomp_per_cl  \\\n0  46702.txt      19        3.00          1.000000          0.00   \n1  47208.txt     153        2.64          1.195993          0.04   \n2  28211.txt      21        2.00          0.000000          0.00   \n3  48093.txt      25        2.00          0.577350          0.00   \n4  19060.txt      76        2.30          1.187434          0.30   \n\n   advcl_per_cl  agent_per_cl  cc_per_cl  ccomp_per_cl  conj_per_cl  ...  \\\n0          0.00          0.00        0.0          0.00         0.00  ...   \n1          0.16          0.04        0.0          0.24         0.08  ...   \n2          0.00          0.00        0.0          0.00         0.00  ...   \n3          0.00          0.00        0.0          0.50         0.00  ...   \n4          0.00          0.00        0.1          0.00         0.20  ...   \n\n   prep_per_cl  prepc_per_cl  prt_per_cl  tmod_per_cl  xcomp_per_cl  \\\n0     0.500000          0.00         0.0          0.0      0.500000   \n1     0.320000          0.04         0.0          0.0      0.120000   \n2     0.000000          0.00         0.0          0.0      0.000000   \n3     0.333333          0.00         0.0          0.0      0.166667   \n4     0.400000          0.00         0.0          0.0      0.200000   \n\n   xsubj_per_cl  advmod_per_cl  aux_per_cl  auxpass_per_cl  modal_per_cl  \n0           0.0           0.00         0.5            0.00      0.000000  \n1           0.0           0.32         0.2            0.04      0.080000  \n2           0.0           0.00         0.0            0.00      0.000000  \n3           0.0           0.00         0.0            0.00      0.166667  \n4           0.0           0.00         0.4            0.00      0.000000  \n\n[5 rows x 34 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>nwords</th>\n      <th>cl_av_deps</th>\n      <th>cl_ndeps_std_dev</th>\n      <th>acomp_per_cl</th>\n      <th>advcl_per_cl</th>\n      <th>agent_per_cl</th>\n      <th>cc_per_cl</th>\n      <th>ccomp_per_cl</th>\n      <th>conj_per_cl</th>\n      <th>...</th>\n      <th>prep_per_cl</th>\n      <th>prepc_per_cl</th>\n      <th>prt_per_cl</th>\n      <th>tmod_per_cl</th>\n      <th>xcomp_per_cl</th>\n      <th>xsubj_per_cl</th>\n      <th>advmod_per_cl</th>\n      <th>aux_per_cl</th>\n      <th>auxpass_per_cl</th>\n      <th>modal_per_cl</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46702.txt</td>\n      <td>19</td>\n      <td>3.00</td>\n      <td>1.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.500000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.5</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47208.txt</td>\n      <td>153</td>\n      <td>2.64</td>\n      <td>1.195993</td>\n      <td>0.04</td>\n      <td>0.16</td>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.24</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.320000</td>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.120000</td>\n      <td>0.0</td>\n      <td>0.32</td>\n      <td>0.2</td>\n      <td>0.04</td>\n      <td>0.080000</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28211.txt</td>\n      <td>21</td>\n      <td>2.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48093.txt</td>\n      <td>25</td>\n      <td>2.00</td>\n      <td>0.577350</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>0.333333</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.166667</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.166667</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19060.txt</td>\n      <td>76</td>\n      <td>2.30</td>\n      <td>1.187434</td>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.1</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>...</td>\n      <td>0.400000</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.200000</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.4</td>\n      <td>0.00</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 34 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taassc.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "    filename  nwords     MLS        MLT        MLC   C_S      VP_T   C_T  \\\n0  46702.txt      19  19.000  19.000000  19.000000  1.00  2.000000  1.00   \n1  47208.txt     153  19.125  21.857143  10.928571  1.75  2.857143  2.00   \n2  28211.txt      21  21.000  21.000000  21.000000  1.00  1.000000  1.00   \n3  48093.txt      25  25.000  25.000000   8.333333  3.00  6.000000  3.00   \n4  19060.txt      76  19.000  19.000000  15.200000  1.25  2.000000  1.25   \n\n       DC_C  DC_T    T_S      CT_T      CP_T      CP_C      CN_T      CN_C  \n0  0.000000  0.00  1.000  0.000000  2.000000  2.000000  2.000000  2.000000  \n1  0.500000  1.00  0.875  0.714286  0.428571  0.214286  2.571429  1.285714  \n2  0.000000  0.00  1.000  0.000000  3.000000  3.000000  2.000000  2.000000  \n3  0.666667  2.00  1.000  1.000000  0.000000  0.000000  3.000000  1.000000  \n4  0.200000  0.25  1.000  0.250000  0.750000  0.600000  3.250000  2.600000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>nwords</th>\n      <th>MLS</th>\n      <th>MLT</th>\n      <th>MLC</th>\n      <th>C_S</th>\n      <th>VP_T</th>\n      <th>C_T</th>\n      <th>DC_C</th>\n      <th>DC_T</th>\n      <th>T_S</th>\n      <th>CT_T</th>\n      <th>CP_T</th>\n      <th>CP_C</th>\n      <th>CN_T</th>\n      <th>CN_C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46702.txt</td>\n      <td>19</td>\n      <td>19.000</td>\n      <td>19.000000</td>\n      <td>19.000000</td>\n      <td>1.00</td>\n      <td>2.000000</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47208.txt</td>\n      <td>153</td>\n      <td>19.125</td>\n      <td>21.857143</td>\n      <td>10.928571</td>\n      <td>1.75</td>\n      <td>2.857143</td>\n      <td>2.00</td>\n      <td>0.500000</td>\n      <td>1.00</td>\n      <td>0.875</td>\n      <td>0.714286</td>\n      <td>0.428571</td>\n      <td>0.214286</td>\n      <td>2.571429</td>\n      <td>1.285714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28211.txt</td>\n      <td>21</td>\n      <td>21.000</td>\n      <td>21.000000</td>\n      <td>21.000000</td>\n      <td>1.00</td>\n      <td>1.000000</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48093.txt</td>\n      <td>25</td>\n      <td>25.000</td>\n      <td>25.000000</td>\n      <td>8.333333</td>\n      <td>3.00</td>\n      <td>6.000000</td>\n      <td>3.00</td>\n      <td>0.666667</td>\n      <td>2.00</td>\n      <td>1.000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19060.txt</td>\n      <td>76</td>\n      <td>19.000</td>\n      <td>19.000000</td>\n      <td>15.200000</td>\n      <td>1.25</td>\n      <td>2.000000</td>\n      <td>1.25</td>\n      <td>0.200000</td>\n      <td>0.25</td>\n      <td>1.000</td>\n      <td>0.250000</td>\n      <td>0.750000</td>\n      <td>0.600000</td>\n      <td>3.250000</td>\n      <td>2.600000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taassc_sca.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "    filename  nwords  cl_av_deps  cl_ndeps_std_dev  acomp_per_cl  \\\n0  46702.txt      19        3.00          1.000000          0.00   \n1  47208.txt     153        2.64          1.195993          0.04   \n2  28211.txt      21        2.00          0.000000          0.00   \n3  48093.txt      25        2.00          0.577350          0.00   \n4  19060.txt      76        2.30          1.187434          0.30   \n\n   advcl_per_cl  agent_per_cl  cc_per_cl  ccomp_per_cl  conj_per_cl  ...  \\\n0          0.00          0.00        0.0          0.00         0.00  ...   \n1          0.16          0.04        0.0          0.24         0.08  ...   \n2          0.00          0.00        0.0          0.00         0.00  ...   \n3          0.00          0.00        0.0          0.50         0.00  ...   \n4          0.00          0.00        0.1          0.00         0.20  ...   \n\n       VP_T   C_T      DC_C  DC_T    T_S      CT_T      CP_T      CP_C  \\\n0  2.000000  1.00  0.000000  0.00  1.000  0.000000  2.000000  2.000000   \n1  2.857143  2.00  0.500000  1.00  0.875  0.714286  0.428571  0.214286   \n2  1.000000  1.00  0.000000  0.00  1.000  0.000000  3.000000  3.000000   \n3  6.000000  3.00  0.666667  2.00  1.000  1.000000  0.000000  0.000000   \n4  2.000000  1.25  0.200000  0.25  1.000  0.250000  0.750000  0.600000   \n\n       CN_T      CN_C  \n0  2.000000  2.000000  \n1  2.571429  1.285714  \n2  2.000000  2.000000  \n3  3.000000  1.000000  \n4  3.250000  2.600000  \n\n[5 rows x 48 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>nwords</th>\n      <th>cl_av_deps</th>\n      <th>cl_ndeps_std_dev</th>\n      <th>acomp_per_cl</th>\n      <th>advcl_per_cl</th>\n      <th>agent_per_cl</th>\n      <th>cc_per_cl</th>\n      <th>ccomp_per_cl</th>\n      <th>conj_per_cl</th>\n      <th>...</th>\n      <th>VP_T</th>\n      <th>C_T</th>\n      <th>DC_C</th>\n      <th>DC_T</th>\n      <th>T_S</th>\n      <th>CT_T</th>\n      <th>CP_T</th>\n      <th>CP_C</th>\n      <th>CN_T</th>\n      <th>CN_C</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46702.txt</td>\n      <td>19</td>\n      <td>3.00</td>\n      <td>1.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47208.txt</td>\n      <td>153</td>\n      <td>2.64</td>\n      <td>1.195993</td>\n      <td>0.04</td>\n      <td>0.16</td>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.24</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>2.857143</td>\n      <td>2.00</td>\n      <td>0.500000</td>\n      <td>1.00</td>\n      <td>0.875</td>\n      <td>0.714286</td>\n      <td>0.428571</td>\n      <td>0.214286</td>\n      <td>2.571429</td>\n      <td>1.285714</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28211.txt</td>\n      <td>21</td>\n      <td>2.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48093.txt</td>\n      <td>25</td>\n      <td>2.00</td>\n      <td>0.577350</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>6.000000</td>\n      <td>3.00</td>\n      <td>0.666667</td>\n      <td>2.00</td>\n      <td>1.000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19060.txt</td>\n      <td>76</td>\n      <td>2.30</td>\n      <td>1.187434</td>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.1</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>...</td>\n      <td>2.000000</td>\n      <td>1.25</td>\n      <td>0.200000</td>\n      <td>0.25</td>\n      <td>1.000</td>\n      <td>0.250000</td>\n      <td>0.750000</td>\n      <td>0.600000</td>\n      <td>3.250000</td>\n      <td>2.600000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 48 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taassc_merged = pd.merge(taassc, taassc_sca)\n",
    "taassc_merged.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "    filename  nwords  cl_av_deps  cl_ndeps_std_dev  acomp_per_cl  \\\n0  46702.txt      19        3.00          1.000000          0.00   \n1  47208.txt     153        2.64          1.195993          0.04   \n2  28211.txt      21        2.00          0.000000          0.00   \n3  48093.txt      25        2.00          0.577350          0.00   \n4  19060.txt      76        2.30          1.187434          0.30   \n\n   advcl_per_cl  agent_per_cl  cc_per_cl  ccomp_per_cl  conj_per_cl  ...  \\\n0          0.00          0.00        0.0          0.00         0.00  ...   \n1          0.16          0.04        0.0          0.24         0.08  ...   \n2          0.00          0.00        0.0          0.00         0.00  ...   \n3          0.00          0.00        0.0          0.50         0.00  ...   \n4          0.00          0.00        0.1          0.00         0.20  ...   \n\n     T_S      CT_T      CP_T      CP_C      CN_T      CN_C  answer_id  \\\n0  1.000  0.000000  2.000000  2.000000  2.000000  2.000000      46702   \n1  0.875  0.714286  0.428571  0.214286  2.571429  1.285714      47208   \n2  1.000  0.000000  3.000000  3.000000  2.000000  2.000000      28211   \n3  1.000  1.000000  0.000000  0.000000  3.000000  1.000000      48093   \n4  1.000  0.250000  0.750000  0.600000  3.250000  2.600000      19060   \n\n        L1  level_id  anon_id  \n0   Arabic         3      es5  \n1   Arabic         4      dw3  \n2  Turkish         5      em7  \n3  Chinese         3      fq6  \n4  Chinese         5      ck3  \n\n[5 rows x 52 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>nwords</th>\n      <th>cl_av_deps</th>\n      <th>cl_ndeps_std_dev</th>\n      <th>acomp_per_cl</th>\n      <th>advcl_per_cl</th>\n      <th>agent_per_cl</th>\n      <th>cc_per_cl</th>\n      <th>ccomp_per_cl</th>\n      <th>conj_per_cl</th>\n      <th>...</th>\n      <th>T_S</th>\n      <th>CT_T</th>\n      <th>CP_T</th>\n      <th>CP_C</th>\n      <th>CN_T</th>\n      <th>CN_C</th>\n      <th>answer_id</th>\n      <th>L1</th>\n      <th>level_id</th>\n      <th>anon_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46702.txt</td>\n      <td>19</td>\n      <td>3.00</td>\n      <td>1.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>46702</td>\n      <td>Arabic</td>\n      <td>3</td>\n      <td>es5</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47208.txt</td>\n      <td>153</td>\n      <td>2.64</td>\n      <td>1.195993</td>\n      <td>0.04</td>\n      <td>0.16</td>\n      <td>0.04</td>\n      <td>0.0</td>\n      <td>0.24</td>\n      <td>0.08</td>\n      <td>...</td>\n      <td>0.875</td>\n      <td>0.714286</td>\n      <td>0.428571</td>\n      <td>0.214286</td>\n      <td>2.571429</td>\n      <td>1.285714</td>\n      <td>47208</td>\n      <td>Arabic</td>\n      <td>4</td>\n      <td>dw3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28211.txt</td>\n      <td>21</td>\n      <td>2.00</td>\n      <td>0.000000</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>3.000000</td>\n      <td>2.000000</td>\n      <td>2.000000</td>\n      <td>28211</td>\n      <td>Turkish</td>\n      <td>5</td>\n      <td>em7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48093.txt</td>\n      <td>25</td>\n      <td>2.00</td>\n      <td>0.577350</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.0</td>\n      <td>0.50</td>\n      <td>0.00</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>48093</td>\n      <td>Chinese</td>\n      <td>3</td>\n      <td>fq6</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19060.txt</td>\n      <td>76</td>\n      <td>2.30</td>\n      <td>1.187434</td>\n      <td>0.30</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>0.1</td>\n      <td>0.00</td>\n      <td>0.20</td>\n      <td>...</td>\n      <td>1.000</td>\n      <td>0.250000</td>\n      <td>0.750000</td>\n      <td>0.600000</td>\n      <td>3.250000</td>\n      <td>2.600000</td>\n      <td>19060</td>\n      <td>Chinese</td>\n      <td>5</td>\n      <td>ck3</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taassc_merged[\"answer_id\"] = taassc_merged[\"filename\"].map(lambda x: int(x[:-4]))\n",
    "taassc_merged[\"L1\"] = taassc_merged[\"answer_id\"].map(lambda x: pelic[pelic[\"answer_id\"] == x][\"L1\"].values[0])\n",
    "taassc_merged[\"level_id\"] = taassc_merged[\"answer_id\"].map(lambda x: pelic[pelic[\"answer_id\"] == x][\"level_id\"].values[0])\n",
    "taassc_merged[\"anon_id\"] = taassc_merged[\"answer_id\"].map(lambda x: pelic[pelic[\"answer_id\"] == x][\"anon_id\"].values[0])\n",
    "taassc_merged.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "   answer_id anon_id       L1  level_id    T_S        MLT   C_T        MLC  \\\n0      46702     es5   Arabic         3  1.000  19.000000  1.00  19.000000   \n1      47208     dw3   Arabic         4  0.875  21.857143  2.00  10.928571   \n2      28211     em7  Turkish         5  1.000  21.000000  1.00  21.000000   \n3      48093     fq6  Chinese         3  1.000  25.000000  3.00   8.333333   \n4      19060     ck3  Chinese         5  1.000  19.000000  1.25  15.200000   \n\n   prep_per_cl  mark_per_cl  \n0     0.500000          0.0  \n1     0.320000          0.2  \n2     0.000000          0.0  \n3     0.333333          0.0  \n4     0.400000          0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>answer_id</th>\n      <th>anon_id</th>\n      <th>L1</th>\n      <th>level_id</th>\n      <th>T_S</th>\n      <th>MLT</th>\n      <th>C_T</th>\n      <th>MLC</th>\n      <th>prep_per_cl</th>\n      <th>mark_per_cl</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>46702</td>\n      <td>es5</td>\n      <td>Arabic</td>\n      <td>3</td>\n      <td>1.000</td>\n      <td>19.000000</td>\n      <td>1.00</td>\n      <td>19.000000</td>\n      <td>0.500000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47208</td>\n      <td>dw3</td>\n      <td>Arabic</td>\n      <td>4</td>\n      <td>0.875</td>\n      <td>21.857143</td>\n      <td>2.00</td>\n      <td>10.928571</td>\n      <td>0.320000</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>28211</td>\n      <td>em7</td>\n      <td>Turkish</td>\n      <td>5</td>\n      <td>1.000</td>\n      <td>21.000000</td>\n      <td>1.00</td>\n      <td>21.000000</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48093</td>\n      <td>fq6</td>\n      <td>Chinese</td>\n      <td>3</td>\n      <td>1.000</td>\n      <td>25.000000</td>\n      <td>3.00</td>\n      <td>8.333333</td>\n      <td>0.333333</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>19060</td>\n      <td>ck3</td>\n      <td>Chinese</td>\n      <td>5</td>\n      <td>1.000</td>\n      <td>19.000000</td>\n      <td>1.25</td>\n      <td>15.200000</td>\n      <td>0.400000</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taassc_measures = taassc_merged[[\"answer_id\", \"anon_id\", \"L1\", \"level_id\", \"T_S\", \"MLT\", \"C_T\", \"MLC\", \"prep_per_cl\", \"mark_per_cl\"]]\n",
    "taassc_measures.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pickle the cleaned TAASSC data for analysis:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# pd.to_pickle(taassc_measures, \"data_samples/taassc-measures.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}